{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intermediate-vacation",
   "metadata": {},
   "source": [
    "<h1>Opdracht: Dataloader</h1><p>\n",
    "    <h5>Machine learning<p>Hogeschool Utecht<p>Olav Vijlbrief</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "transparent-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.dataloader import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-throw",
   "metadata": {},
   "source": [
    "<H1>Doel van de opdracht</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    Het doel van de opdracht is om dataloader te maken voor tijdseriedata uit een EEG. Om te bepalen of iemand zijn ogen wel of niet open heeft. Binnen de opdracht zijn er verschillende niveau's. \n",
    "    <p><p>\n",
    "        Ik heb getracht een universele dataloader te maken, waarin verschillende opties zijn geïntegreerd voor deze dataset. Zo is er een functie window en padding toegevoegd. Kan er gekozen worden hoe de data gesplits moeten, per chunck of niet afhankelijk van het doel van de ML. En daarvoor is er ook de keuze toegevoegd om de data random op te splitsen in een train en test set, of juist chronologisch. Ook de output is daarvoor aan te passen, per sequence kan er 1 outcome worden gegeven, maar ook per tijdsstap. Er is ook een functie om de data per batch te krijgen. \n",
    "</font>            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-pocket",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Hieronder wordt de code weergegeven hoe een dataset ingeladen wordt het object Data aangemaakt.\n",
    "<BR> In de kopjes er onder wordt uitgelegd wat alle input parameters zijn en hoe deze het resultaat beïnvloeden.\n",
    "    <BR> Daarna word de code ook een aantal keer aangeroepen om te laten zien wat het verschil is.\n",
    "        </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-speaker",
   "metadata": {},
   "source": [
    "```python\n",
    "Data  = Dataset(\n",
    "        url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\",\n",
    "        path=\"../data\",\n",
    "        filename=\"eeg\",\n",
    "        per_chunk=True,\n",
    "        continuous_window=False,\n",
    "        seq_length=25,\n",
    "        min_seq_length=15,\n",
    "        fractions=[0.7, 0.3, 0],\n",
    "        random=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-saturday",
   "metadata": {},
   "source": [
    "<H1>Inladen van de data</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    De dataloader checkt of de dataset als is binnengehaald, zo niet dan wordt de data gedownload vanaf de opgegeven url. En opgeslagen op de locatie die wordt meegegeven met path en filename. \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-finger",
   "metadata": {},
   "source": [
    "<H1>Creëren van sequenties</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    In de code zitten 4 verschillende opties geïmplementeerd om de dataset op te splitsen naar sequenties. \n",
    "    <BR>- De eerste optie is om ervoor te kiezen sequenties te maken per chunk (dus binnen een deel met gelijke outcome)\n",
    "    <BR>- De tweede optie splits de gehele dataset op, ongeacht de outcome.\n",
    "<p>\n",
    "    Vervolgens is er de optie om te kiezen voor aan elkaar grenzende sequenties of elkaar overlappende sequenties. \n",
    "    <BR>- In Optie A worden de sequenties aansluitende op elkaar gegenereerd. \n",
    "    <BR>- In Optie B begint iedere sequentie 1 tijdstap later dan de vorige. \n",
    "        \n",
    "Optie 1 of 2 wordt uitgevoerd voordat een window wordt toegepast, keuze A en B zitten beide in de window functie. \n",
    "\n",
    "<img src='.\\data\\seq.png'>\n",
    "        </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-steps",
   "metadata": {},
   "source": [
    "<H1>Window en Padding</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    Bij het aanroepen van de dataset is er de mogelijkheid om een sequentie lengte op te geven voor het toepassen van het window. Echter is er ook de mogelijkheid een minimale lengte op te geven. Als de chunk te korter is dan de gevraagde sequentie lengte, maar aan de minimale lengte wordt wel voldaan. Dan wordt het tekort aan de voorkant aangevuld met extra waardes (0). Ofwel door te kiezen voor een korte minimum lengte dan de gevraagde sequentie lengte wordt padding automatische toegepast. \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-hands",
   "metadata": {},
   "source": [
    "<H1>Splitsen naar Train/Test Validatie set</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    Bij het aanroepen moet ook worden meegegeven met welke verhouding de data (sequenties) moet worden gesplits. Hiervoor wordt een list meegegeven met 3 fracties (totale optelsom 1). Ook kan er meegegeven worden of de data random moet worden gesplits of niet. Als dit niet het geval is worden ze chronologisch gesplitst, dus eerst de trainingsdata, daarna de testdata en als laatst de validatiedata.  \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-devon",
   "metadata": {},
   "source": [
    "<H1>Batch</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    De functie batch is onderdeel van de dataloader. Aan deze functie geef je mee of je de train, test of validatie set wilt ontvangen. Welke batchsize en of je 1 of meer outcomes wilt. (zie hieronder). \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-delay",
   "metadata": {},
   "source": [
    "<H1>Outcome</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    In de code zitten 2 verschillende opties voor de outcome. \n",
    "    <BR>- De eerste optie is om ervoor te kiezen sequenties te maken per chunk (dus binnen een deel met gelijke outcome)\n",
    "    <BR>- De tweede optie splits de gehele dataset op, ongeacht de outcome.\n",
    "\n",
    "<img src='.\\data\\outcome.png'>\n",
    "        </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-examination",
   "metadata": {},
   "source": [
    "<H1>Voorbeelden</H1>\n",
    "<font color='navy'>\n",
    "<p>\n",
    "    Hieronder wordt de code ingezet voor een aantal voorbeelden. \n",
    "    <p>- In het ene voorbeeld doen we optie 1A, dus per batch en geen overlap tussen de verschillende chunks\n",
    "        <br>We kiezen hier voor een sequentie lengte van 25 en een minimum van 15, want we wisten al dat de minimale lengte 21 was, dus hier zal padding moeten worden toegepast. Verder wordt de data verdeelt tussen 70% training en 30% test data. Deze data wordt random verdeelt. Dat kan aangezien er geen overlap zit tussen de datasets en \n",
    "    <p>- Het andere voorbeeld is op basis van optie 2B, dus al geheel met overlap\n",
    "        <br>Omdat er voor gekozen is om de hele set op te splitsen is padding hier niet van toepassing. Ook hier wordt de data 70/30 verdeelt. Echter kan er hier niet worden gekozen voor een random splitsing anders lekt er testdata in de trainingsdata. Dit omdat dezelfde data in meerder sequenties voorkomt.\n",
    "        </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "robust-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has already been downloaded, file exists\n",
      "applied padding, sequence length: 21 ==> 25\n",
      "Data split per chunk:\n",
      "Number of chunks: 24\n",
      "Average chunk size: 624\n",
      "Minimum chunk size: 21\n",
      "Maximum chunk size: 2401\n"
     ]
    }
   ],
   "source": [
    "DL_per_chunk = Dataset(\n",
    "                        url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\",\n",
    "                        path=\"../data\",\n",
    "                        filename=\"eeg\",\n",
    "                        per_chunk=True,\n",
    "                        continuous_window=False,\n",
    "                        seq_length=25,\n",
    "                        min_seq_length=15,\n",
    "                        fractions=[0.7, 0.3, 0],\n",
    "                        random=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-metropolitan",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Uit de printout zien we dat er 1 sequence is aangevuld van 21 naar 25. \n",
    "Dat de data is opgesplits in 24 chuncks met een minimum lengte van 21. Het gemiddelde en maximum zijn ook weergegeven. \n",
    "<P>\n",
    "Nu kijken we naar het 2de voorbeeld\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "turkish-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has already been downloaded, file exists\n"
     ]
    }
   ],
   "source": [
    "DL_continue = Dataset(\n",
    "                        url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\",\n",
    "                        path=\"../data\",\n",
    "                        filename=\"eeg\",\n",
    "                        per_chunk=False,\n",
    "                        continuous_window=True,\n",
    "                        seq_length=25,\n",
    "                        min_seq_length=15,\n",
    "                        fractions=[0.7, 0.3, 0],\n",
    "                        random=False,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-wallace",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Hier zien we ook in de print output dat er geen padding is toegepast, geen chunks zijn vastgesteld, want dat is in dit geval niet van toepassing. <P> We kunnen nu ook kijken naar het verschil in lengte van de beide dataset. Ofwel het aantal sequenties dat is vastgesteld.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-environment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal sequenties als je per chunk splits en geen overlap hebt:     590\n",
      "Aantal sequenties als je niet per chunk splits en wle overlap hebt: 14956\n"
     ]
    }
   ],
   "source": [
    "print(f'Aantal sequenties als je per chunk splits en geen overlap hebt:     {len(DL_per_chunk)}')\n",
    "print(f'Aantal sequenties als je niet per chunk splits en wle overlap hebt: {len(DL_continue)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-aviation",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Zoals te zien is, is er een groot verschil tussen het aantal sequenties wat dit opleverd. Dat is logische om 2 redenen. \n",
    "Om te beginnen zijn er 25x meer mogelijke sequenties te maken als je kies voor optie B, een continue opslitsing. \n",
    "590x25 = 14750. Echter verklaard dit nog niet het gehele verschil. Maar dat is toe te schrijven aan het aantal chuncks. Door het aantal overgangen neemt het aantal mogelijke sequenties een klein beetje af. \n",
    "<P>\n",
    "Het is mogelijk één enkele sequentie op te halen door de functie __getitem__.  Deze geeft de sequentie terug inclusief de outcome. vandaar dat de dimensie hiervan 25 (lengte van een sequentie) bij 15 (14 features + 1 outcome) is.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "white-plate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DL_per_chunk.__getitem__(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-thanks",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Nu is het tijd om te kijken naar de batch function, dit is een streaming function. Dus je maakt eerst en generator object aan. Dit doen we ook voor beide opties. Hierbij kan je een batchsize ingeven, in beide gevalllen kiezen we even voor 32. Het target geeft aan of je de train, test of validatie set wilt gebruiken. Als laatste is er de optie voor single catagory. Bij True geeft deze dus maar 1 outcome per sequentie, in het andere geval per tijdstap een outcome. \n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fitted-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator_per_chunck = DL_per_chunk.batch(batchsize=32,\n",
    "                                                target=\"train\",\n",
    "                                                single_cat=True)\n",
    "\n",
    "batch_generator_continue = DL_per_chunk.batch(batchsize=32,\n",
    "                                              target=\"train\",\n",
    "                                              single_cat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-professional",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Hieronder bekijken we de uitkomst van de functie. We beginnen met die per chunck\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "irish-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De dimensies van de batch voor X is: torch.Size([32, 25, 14])\n",
      "De dimensies van de batch voor Y is: torch.Size([32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "X, Y = next(batch_generator_per_chunck)\n",
    "\n",
    "print(f'De dimensies van de batch voor X is: {X.shape}')\n",
    "print(f'De dimensies van de batch voor Y is: {Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-extra",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "Zoals hierboven te zien, zijn de dimensies van de batch, 32 sequenties van 25 tijdstappen met ieder 14 features.\n",
    "Voor de uitkomst Y is dit dus 32 sequenties met 1 waarde.\n",
    "\n",
    "Hetzelfde kunnen we nu doen voor de andere generator\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handed-cambridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De dimenties van de batch voor X is: torch.Size([32, 25, 14])\n",
      "De dimenties van de batch voor Y is: torch.Size([32, 25, 1])\n"
     ]
    }
   ],
   "source": [
    "X, Y = next(batch_generator_continue)\n",
    "\n",
    "print(f'De dimenties van de batch voor X is: {X.shape}')\n",
    "print(f'De dimenties van de batch voor Y is: {Y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-filing",
   "metadata": {},
   "source": [
    "<font color='navy'>\n",
    "De dimensie van X zijn hetzelfde gebleven alleen de van de Y zijn veranderd, deze geeft nu voor iedere tijdstip een outcome value. Daarom dus nu een shape van 32x25x1\n",
    "\n",
    "Met al deze functies is de dataloader naar mijn idee een complete tool geworden\n",
    "    </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
